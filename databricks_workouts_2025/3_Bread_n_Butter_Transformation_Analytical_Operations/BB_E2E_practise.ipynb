{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16ce7620-3be4-4c67-97e7-46e09a953c96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#importing spark session\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark=SparkSession.builder.getOrCreate()\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType, IntegerType, ShortType, LongType, DoubleType,FloatType,DateType,BooleanType,TimestampType\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "from pyspark.sql.functions import lit,initcap,col,initcap\n",
    "\n",
    "struct=StructType([StructField('id',StringType(), True),StructField('firstname',StringType(), True),StructField('lastname',StringType(), True),StructField('age',StringType(), True),StructField('profession',StringType(), True)])\n",
    "\n",
    "#reading the csv file and converting it into spark dataframe adding schema\n",
    "rawdf1=spark.read.schema(struct).csv(\"/Volumes/workspace/wd36schema/ingestion_volume/source/custsmodified\",sep=',',mode=\"permissive\")\n",
    "rawdf1.show(20)\n",
    "rawdf1.count()\n",
    "\n",
    "#----Active Data Munging----\n",
    "\n",
    "#cleansing\n",
    "#na.drop will remove the rows which has null values in all the columns, if subset is specified then records having nulls in the specified columns will be removed\n",
    "cleanseddf1=rawdf1.na.drop(how='all',subset=[\"firstname\",\"lastname\"])\n",
    "display(cleanseddf1.count())\n",
    "\n",
    "#scrubbing\n",
    "\n",
    "#na.fill will fill the nulls with provided values in specified coulmns\n",
    "scrubbeddf1=cleanseddf1.na.fill(\"not provided\",subset=[\"lastname\",\"profession\"])\n",
    "\n",
    "#na.replace will replace a value with another in given subset\n",
    "scrubbeddf2=scrubbeddf1.na.replace(\"not provided\",\"NA\",subset=[\"lastname\"])\n",
    "repl_dict_list={\"Actor\":\"Celebrity\",\"Pilot\":\"Captain\"}\n",
    "scrubbeddf3=scrubbeddf2.na.replace(repl_dict_list,subset=[\"profession\"])\n",
    "display(scrubbeddf3.show(10))\n",
    "\n",
    "#De-duplication\n",
    "\n",
    "#removing row level duplicate using distinct\n",
    "dedupdf1=scrubbeddf3.distinct()\n",
    "display(dedupdf1.show(10))\n",
    "\n",
    "\n",
    "#removing column level duplicate using dropDuplicates\n",
    "dedupdf2=dedupdf1.coalesce(1).dropDuplicates(['id'])\n",
    "display(dedupdf2.show(10))\n",
    "\n",
    "#display(dedupdf1.where(\"id in ('4000003')\"))\n",
    "#below will dlete the duplicate records prioritised on id and retain the record with highest age for the id=4000003, using order by\n",
    "#dedupdf1.coalesce(1).where(\"id in('4000003')\").orderBy([\"id\",\"age\"], ascending=[True,False]).show()\n",
    "#dedupdf1.coalesce(1).where(\"id in('4000003')\").orderBy([\"id\",\"age\"], ascending=[True,False]).dropDuplicates(['id']).show()\n",
    "\n",
    "#Data Standardization\n",
    "\n",
    "#Standardization 1 - Column Enrichment\n",
    "stddf1=dedupdf2.withColumn(\"sourcesystem\",lit(\"source\"))\n",
    "display(stddf1.show(10))\n",
    "\n",
    "#standardization 2 - Column Uniformity\n",
    "stddf2 =stddf1.withColumn(\"profession\",initcap(stddf1.profession))\n",
    "display(stddf2.show(10))\n",
    "\n",
    "#standardization 3 - Column Transformation\n",
    "\n",
    "#stddf2.select(col(\"age\")).distinct().show()\n",
    "#stddf2.select(col(\"id\")).distinct().orderBy(\"id\").show()\n",
    "\n",
    "#rlike is regular expression like function that help us identify any string data in our DF column\n",
    "#stddf2.where(\"id like 't%'\").show()\n",
    "#stddf2.where(\"id rlike 'a-z'\").show()\n",
    "#stddf2.where(\"id rlike 'A-Z'\").show()\n",
    "stddf2.where(\"id rlike '[a-zA-Z]'\").show()\n",
    "#stddf2.where(\"id rlike '[A-Z]'\").show()\n",
    "stddf2.where(\"age rlike '[^0-9]'\").show() #checking for any non number values in age column\n",
    "#stddf2.where(\"age rlike '0-9'\").show() #checking for any number values in age column\n",
    "\n",
    "#stdfdf3 = stddf2.withColumn(\"id\",replace(col(\"id\"),\"ten\",\"10\")) #to replace only one value\n",
    "#display(stddf3.where (\"firstname = 'Elsie'\")) -#to check if id is updated successfully\n",
    "repl_list={\"one\":\"1\",\"two\":\"2\",\"three\":\"3\",\"four\":\"4\",\"five\":\"5\",\"six\":\"6\",\"seven\":\"7\",\"eight\":\"8\",\"nine\":\"9\",\"ten\":\"10\"}\n",
    "stdf3 = stddf2.na.replace(repl_list,subset=[\"id\"]) #created dictonary to replace list of \n",
    "stddf3 = stddf2.withColumn(\"age\",regexp_replace(\"age\",\"-\",\"\")) #using regular expression replace function to replace 7-7 with 77\n",
    "\n",
    "#standardization 4 - Datatype Standardization\n",
    "stddf4=stddf3.withColumn(\"id\", stddf3.id.cast(IntegerType())).withColumn(\"age\", stddf3.age.cast(ShortType()))\n",
    "stddf4.printSchema()\n",
    "\n",
    "#standardization 5 - ColumnRename\n",
    "stddf5=stddf4.withColumnsRenamed({\"id\":\"custid\",\"sourcesystem\":\"srcsys\"})\n",
    "display(stddf5.show(10))\n",
    "\n",
    "#standardization 6 -"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "BB_E2E_practise",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
