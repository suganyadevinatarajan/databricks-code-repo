{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "3d719b29-6c21-4f75-8b81-e718892f1c2c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install word2number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "782e94b6-2b85-42fe-bf71-8a548b40c2f1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark import pipelines as dp\n",
    "from pyspark.sql.functions import *\n",
    "from word2number import w2n\n",
    "\n",
    "#Python to UDF\n",
    "def word_to_num_logic(value):\n",
    "    if value is None:\n",
    "        return None\n",
    "    try:\n",
    "        return int(value)\n",
    "    except:\n",
    "        try:\n",
    "            return w2n.word_to_num(str(value).lower())\n",
    "        except:\n",
    "            return None\n",
    "        \n",
    "convert_age_udf = udf(word_to_num_logic)\n",
    "\n",
    "@dp.materialized_view(\n",
    "    name=\"silver_staff_dlt2\",\n",
    "    comment=\"Standardized staff data\"\n",
    ")\n",
    "def silver_staff_dlt1():\n",
    "    return (\n",
    "        spark.read.table(\"bronze_staff_data1\")\n",
    "        .select(\n",
    "            col(\"shipment_id\").cast(\"bigint\"),\n",
    "            convert_age_udf(col(\"age\")).alias(\"age\"),\n",
    "            lower(col(\"role\")).alias(\"role\"),\n",
    "            initcap(col(\"hub_location\")).alias(\"origin_hub_city\"),\n",
    "            current_timestamp().alias(\"load_dt\"),\n",
    "            concat_ws(\" \", col(\"first_name\"), col(\"last_name\")).alias(\"staff_full_name\"),\n",
    "            initcap(col(\"hub_location\")).alias(\"hub_location\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "@dp.materialized_view(\n",
    "    name=\"silver_geotag_dlt2\",\n",
    "    comment=\"Cleaned geotag data\",\n",
    "    table_properties={\"quality\": \"silver\"}\n",
    ")\n",
    "def silver_geotag_dlt2():\n",
    "    return (\n",
    "        spark.read.table(\"bronze_geotag_data1\")\n",
    "        .select(\n",
    "            initcap(col(\"city_name\")).alias(\"city_name\"),\n",
    "            initcap(col(\"country\")).alias(\"masked_hub_location\"),\n",
    "            col(\"latitude\"),\n",
    "            col(\"longitude\")\n",
    "        )\n",
    "        .distinct()\n",
    "    )\n",
    "\n",
    "@dp.materialized_view(\n",
    "    name=\"silver_shipments_dlt2\",\n",
    "    comment=\"Enriched and split shipments data\",\n",
    "    table_properties={\"quality\": \"silver\"}\n",
    ")\n",
    "def silver_shipments_dlt2():\n",
    "    ship_date_col = to_date(col(\"shipment_date\"), \"yy-MM-dd\")\n",
    "    \n",
    "    return (\n",
    "        spark.read.table(\"bronze_shipments_data1\")\n",
    "        .withColumn(\"domain\", lit(\"Logistics\"))\n",
    "        .withColumn(\"ingestion_timestamp\", current_timestamp())\n",
    "        .withColumn(\"is_expedited_flag_initial\", lit(False).cast(\"boolean\"))\n",
    "        .withColumn(\"shipment_date_clean\", ship_date_col)\n",
    "        .withColumn(\"shipment_cost_clean\", round(col(\"shipment_cost\"), 2))\n",
    "        .withColumn(\"shipment_weight_clean\", col(\"shipment_weight_kg\").cast(\"double\"))\n",
    "        .withColumn(\"route_segment\", concat_ws(\"-\", col(\"source_city\"), col(\"destination_city\")))\n",
    "        .withColumn(\"vehicle_identifier\", concat_ws(\"_\", col(\"vehicle_type\"), col(\"shipment_id\")))\n",
    "        .withColumn(\"shipment_year\", year(ship_date_col))\n",
    "        .withColumn(\"shipment_month\", month(ship_date_col))\n",
    "        .withColumn(\"is_weekend\", \n",
    "            when(dayofweek(ship_date_col).isin([1, 7]), True)\n",
    "            .otherwise(False)\n",
    "        )\n",
    "        .withColumn(\"is_expedited\", \n",
    "            when(col(\"shipment_status\").isin([\"IN_TRANSIT\", \"DELIVERED\"]), True)\n",
    "            .otherwise(False)\n",
    "        )\n",
    "        .withColumn(\"cost_per_kg\", round(col(\"shipment_cost\") / col(\"shipment_weight_kg\"), 2))\n",
    "        .withColumn(\"tax_amount\", round(col(\"shipment_cost\") * 0.18, 2))\n",
    "        .withColumn(\"days_since_shipment\", datediff(current_date(), ship_date_col))\n",
    "        .withColumn(\"is_high_value\", \n",
    "            when(col(\"shipment_cost\") > 50000, True)\n",
    "            .otherwise(False))\n",
    "        .withColumn(\"order_prefix\", substring(col(\"order_id\"), 1, 3))\n",
    "        .withColumn(\"order_sequence\", substring(col(\"order_id\"), 4, 10))\n",
    "        .withColumn(\"ship_day\", dayofmonth(ship_date_col))\n",
    "        .withColumn(\"route_lane\", concat_ws(\"->\", col(\"source_city\"), col(\"destination_city\")))\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "silver_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
